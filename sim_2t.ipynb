{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8fd11d6",
   "metadata": {},
   "source": [
    "# Cable Driven Parallel Robot 2T Model Tests\n",
    "#### Created by: Alexander Herdt\n",
    "\n",
    "This notebook is designed to train RL-agents for control of a cable driven parallel robot (CDPR) after cable break.  The CDPR is described as an RL-environment and has two translational degrees of freedom (2T) and a point mass endeffector/platform in a YZ-coordinate system. The specifications are derived by simplification of the CABLAR robot developed by the Chair of Mechatronics of the University of Duisburg-Essen. \n",
    "\n",
    "The following implementation is primarily based on the stable-baselines3 package which uses OpenAI gym as a basis for creating RL environments and Pytorch for training models with GPU integration. Furthermore Tensorboard can be used as a tool for observing leaning processes. Please refer to https://stable-baselines3.readthedocs.io/en/master/index.html for additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7034a7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "223fd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import timeit\n",
    "import numpy as np\n",
    "from cdpr.utils import *\n",
    "from environment import states\n",
    "from environment.environment import EmergencyStrategyCDPR\n",
    "from environment.observations import *\n",
    "from environment.actions import Action, cable_forces_action, cable_force_gradients_action, platform_wrench_action\n",
    "from environment.rewards import *\n",
    "from environment.tasks import stop_pointmass_task\n",
    "from evaluation import evaluation\n",
    "from evaluation.visualize import *\n",
    "from simulation.cablar import cablar1r2t, cablar2t\n",
    "from simulation.agents import RLAgent\n",
    "from typing import Dict, List, Union\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3 import SAC, PPO\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2351cf0",
   "metadata": {},
   "source": [
    "### CDPR Setup\n",
    "Specify a cable driven parallel robot that is an instance of the CDPR class and an array coordinates.  \n",
    "The coordinate array is necessary for workspace calculation and initialization of environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a17eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdpr = cablar2t # CDPR Modell\n",
    "env_kwargs = {\"goal\":np.array([[1.47],[1.38]])}\n",
    "cables_idx = [0,2,3] # which cables should be used i.e. a cable that is not specified is considered \"broken\"\n",
    "Ts = 0.005 # timestep \n",
    "max_episode_timesteps = 10000\n",
    "# Coordinate grid for workspace calculation and initialization of environment\n",
    "Y = np.linspace(-5,5,100) \n",
    "Z = np.linspace(0,5,100)\n",
    "# PHI = np.deg2rad(np.arange(-30,30,1))\n",
    "# PHI = np.array([0])\n",
    "coordinates = create_grid_coordinates([Y,Z])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c7e96a",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Define all observation sets and their limits with the `Observation` class.  \n",
    "All observations will be normalized by default to the interval __[-1,1]__ if you do not specify otherwise.  \n",
    "Please use the `ObservationFunction` class and specify which variables will be observed if you would like to define a new observation function.  \n",
    "Any observable variables should be defined as `StateVariable` or `DerivedVariable` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbf6d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe [pose, spatial_velocities, cable_forces] \n",
    "obs0 = Observation(obsfunc0,\n",
    "                   low=[-5,0,-100,-100,150,150,150],\n",
    "                   high=[5,5,100,100,2500,2500,2500])\n",
    "# Observe [pose, velocities, cable_forces, position_error] \n",
    "obs1 = Observation(obsfunc1,\n",
    "                   low=[-5,0,-100,-100,150,150,150,0,0],\n",
    "                   high=[5,5,100,100,2500,2500,2500,10,5])\n",
    "\n",
    "# Observe [pose, velocities, spatial_accelerations, cable_forces] \n",
    "obs2 = Observation(obsfunc2,\n",
    "                   low=[-5,0,-100,-100,-100,-100,150,150,150],\n",
    "                   high=[5,5,100,100,100,100,2500,2500,2500])\n",
    "\n",
    "# Observe [pose, velocities, cable_forces, cable_lengths]\n",
    "obs3 = Observation(obsfunc3,\n",
    "                   low=[-5,0,-100,-100,150,150,150,0,0,0],\n",
    "                   high=[5,5,100,100,2500,2500,2500,10,10,10])\n",
    "\n",
    "# Observe [pose, spatial_velocities, cable_forces, steps] \n",
    "obs4 = Observation(obsfunc1,\n",
    "                   low=[-5,0,-100,-100,150,150,150,0],\n",
    "                   high=[5,5,100,100,2500,2500,2500,10000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2d27125",
   "metadata": {},
   "source": [
    "### Actions\n",
    "Define actions as action functions and action spaces that will be used by the Agent.  \n",
    "If new actions need to be defined please use the `Action` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d12bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "act0 = cable_forces_action\n",
    "act1 = cable_force_gradients_action\n",
    "act2 = platform_wrench_action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9b5c231",
   "metadata": {},
   "source": [
    "### Rewards\n",
    "Define rewards and the parameter values that should be tested.  \n",
    "The parameter values should be in a dict of the form `{\"parameter_name_0\":value, \"parameter_name_1\":value, ...}`.  \n",
    "If new rewards need to be defined please use the `Reward` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f411f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew0 = neg_v_reward\n",
    "rew_params0 = {\"c1\":[1,0.1,0.01],\"c2\":[1,2]}\n",
    "rew1 = pos_v_reward\n",
    "rew_params1 = {\"c1\":[1,0.1,0.01],\"c2\":[1,2]}\n",
    "rew2 = neg_exp_v_reward\n",
    "rew_params2 = {\"c1\":[1,0.1,0.01]}\n",
    "rew3 = pos_exp_v_reward\n",
    "rew_params3 = {\"c1\":[1,0.1,0.01]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24bac3bb",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "Define a task as a set of functions that determine whether termination criteria are met during an eposide.\n",
    "If new tasks need to be defined please use the `Task` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98a100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task0 = stop_pointmass_task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c4aec2c",
   "metadata": {},
   "source": [
    "### Definition of tests\n",
    "Specify each test as a dictiionary `{\"obs\":your_observation, \"act\": your_action, \"rew\": your_reward, \"rew_params\": paramters_to_test, \"task\":your_task}`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ff97b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {\n",
    "        0:{\"obs\":obs0,\n",
    "           \"act\":act1,\n",
    "           \"rew\":rew0,\n",
    "           \"rew_params\":rew_params0,\n",
    "           \"task\":task0},\n",
    "        1:{\"obs\":obs0,\n",
    "           \"act\":act1,\n",
    "           \"rew\":rew1,\n",
    "           \"rew_params\":rew_params1,\n",
    "           \"task\":task0},\n",
    "        2:{\"obs\":obs0,\n",
    "           \"act\":act1,\n",
    "           \"rew\":rew2,\n",
    "           \"rew_params\":rew_params2,\n",
    "           \"task\":task0},\n",
    "        3:{\"obs\":obs0,\n",
    "           \"act\":act1,\n",
    "           \"rew\":rew3,\n",
    "           \"rew_params\":rew_params3,\n",
    "           \"task\":task0},\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e1257",
   "metadata": {},
   "source": [
    "## Testing\n",
    "The testing procedure creates a folder in `models_path` that is named after the current datetime and is referred to as `model_path`. This folder contains a `setup_info.json` file and separate folders for every test.\n",
    "\n",
    "Additional info:\n",
    "- `setup_info.json` describes the configuration of the CDPR simulation and the foldernames for the different tests (a number `t_j` consisting of a testnumber `t` and parameter combination `j`).  \n",
    "- Each test will be repeated once for every seed specified in `seeds` to account for the effect of random initialisation\n",
    "- test folders will contain a trained model that was optained after  `total_timesteps` and a model that achieved the result during evaluations\n",
    "- Evaluations are run after every `eval_freq` timesteps for `n_eval_episodes`\n",
    "- Training logs will be stored in `model_path`+`logs`\n",
    "- Training logs can accessed with **Tensorboard** by opening a python command prompt in the `model_path` folder and entering `tensorboard --logdir logs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17dd4f3",
   "metadata": {},
   "source": [
    "### Specify tests and configurations\n",
    "The tests use default Hyperparameters if not specified otherwise.  \n",
    "TQC: https://sb3-contrib.readthedocs.io/en/master/modules/tqc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = TQC\n",
    "total_timesteps = 1e6 # number of training timesteps\n",
    "eval_freq = 100000 # number of timesteps before each evaluation\n",
    "n_eval_episodes = 30 # number of episodes to run during evalutation\n",
    "use_gSDE = False\n",
    "n_envs = 1\n",
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a19765",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1,42,777]\n",
    "testing_coordinates = coordinates\n",
    "tests_now = list(tests.keys())\n",
    "tests_path = os.path.join(os.getcwd(),\"tests\")\n",
    "models_folder = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# tests_now = [0,1,2]\n",
    "# tests_path = \"\"\n",
    "# models_folder = \"\"\n",
    "model_path = os.path.join(tests_path, models_folder)\n",
    "os.makedirs(model_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd588cfb",
   "metadata": {},
   "source": [
    "### Run testing procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de009ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(model_path,\"logs\")\n",
    "setup_info = os.path.join(model_path, 'setup_info.txt')\n",
    "setup_info = {\"name\":models_folder,\n",
    "              \"cables\": cables_idx,\n",
    "              \"DoF\":\"2T\",\n",
    "              \"Ts\":Ts,\n",
    "              \"total_timesteps\":total_timesteps}\n",
    "\n",
    "test_params = {}\n",
    "test_infos = {}\n",
    "\n",
    "model_num = 1\n",
    "for t, test_num in enumerate(tests_now):\n",
    "    test = tests_now[test_num]\n",
    "    obs = test[\"obs\"]\n",
    "    act = test[\"act\"]\n",
    "    rew = test[\"rew\"]\n",
    "    task = test[\"task\"]\n",
    "    test_infos[t] = {\"obs_desc\":obs.description,\n",
    "                     \"act_desc\":act.description,\n",
    "                    \"rew_desc\": rew.description,\n",
    "                    \"num\":{}}\n",
    "    rew_params = list(test[\"rew_params\"].values())\n",
    "    \n",
    "    for i in range(len(rew_params)):\n",
    "        param = rew_params[i]\n",
    "        for j in range(len(param)):\n",
    "            param_value = param[j]\n",
    "            if type(param_value) == np.ndarray:\n",
    "                rew_params[i][j] = param_value.tolist()\n",
    "    if rew_params:\n",
    "        param_combos = list(itertools.product(*rew_params))\n",
    "    else:\n",
    "        param_combos = [1]\n",
    "    j = 0    \n",
    "    for params in param_combos:\n",
    "        test_infos[t][\"num\"][f\"{t}_{j}\"] = dict(zip(test[\"rew_params\"].keys(),params))\n",
    "        test_infos[t][\"num\"][f\"{t}_{j}\"][\"tb_log_num\"] = {}\n",
    "        for seed in seeds:\n",
    "            test_infos[t][\"num\"][f\"{t}_{j}\"][\"tb_log_num\"][seed] = model_num\n",
    "            model_num +=1\n",
    "        j += 1\n",
    "    \n",
    "setup_info[\"test_infos\"] = test_infos\n",
    "with open(os.path.join(model_path, \"setup_info.json\"),\"w\") as json_file:\n",
    "    json.dump(setup_info, json_file, indent=4, separators = (\",\",\":\"))\n",
    "\n",
    "all_results = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e4ac088",
   "metadata": {},
   "source": [
    "## Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412625b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "mpl.use(\"Agg\")\n",
    "for t in tests_now:\n",
    "    test = tests[t]\n",
    "    obs= test[\"obs\"]\n",
    "    act = test[\"act\"]\n",
    "    rew = test[\"rew\"]\n",
    "    if rew_params:\n",
    "        param_combos = list(itertools.product(*list(test[\"rew_params\"].values())))\n",
    "    else:\n",
    "        param_combos = [1]\n",
    "        \n",
    "    for j, params in enumerate(param_combos):\n",
    "        rew_params = dict(zip(test[\"rew_params\"].keys(),params))\n",
    "        env = EmergencyStrategyCDPR(\n",
    "            cdpr=cdpr,\n",
    "            cables_idx=cables_idx,\n",
    "            Ts=Ts,\n",
    "            max_episode_timesteps=max_episode_timesteps,\n",
    "            coordinates=coordinates,\n",
    "            observation=obs,\n",
    "            action=act,\n",
    "            reward=rew,\n",
    "            task=task,\n",
    "            rew_params=rew_params,\n",
    "            **env_kwargs\n",
    "            )\n",
    "        \n",
    "        for seed in seeds:\n",
    "            # Vectorize environment for faster execution and add a Monitor wrapper for evaluation \n",
    "            vec_env = make_vec_env(lambda: env,\n",
    "                                    seed = seed,\n",
    "                                    monitor_kwargs=dict(info_keywords=(\"is_success\",)),\n",
    "                                    n_envs=n_envs)\n",
    "            # Save path for best evaluated models during training\n",
    "            savedir = os.path.join(model_path, f\"{t}_{j}\",str(seed))\n",
    "            best_model_save_path = os.path.join(savedir, f\"best\")\n",
    "            model_save = os.path.join(savedir,\"Cdpr.zip\")\n",
    "            eval_env = make_vec_env(lambda: env)\n",
    "            eval_callback = EvalCallback(eval_env, n_eval_episodes=n_eval_episodes,\n",
    "                                        best_model_save_path=best_model_save_path,\n",
    "                                        log_path=best_model_save_path, eval_freq=eval_freq,\n",
    "                                        deterministic=True, render=False)\n",
    "            vec_env.seed(seed)\n",
    "            model = algo('MlpPolicy', \n",
    "                            vec_env, \n",
    "                            device='cuda',\n",
    "                            verbose=0, \n",
    "                            seed = seed,\n",
    "                            tensorboard_log=log_path,\n",
    "                            **config)\n",
    "            \n",
    "            # Train the agent\n",
    "            start = datetime.datetime.now()\n",
    "            print(f\"Begin training Model {t}_{j} seed {seed}. Start: {start.strftime('%d.%m.%Y %H:%M:%S')}\")\n",
    "            begin = timeit.default_timer()\n",
    "            model.learn(total_timesteps=int(total_timesteps), callback=eval_callback)\n",
    "            finish = timeit.default_timer()\n",
    "            end = datetime.datetime.now()\n",
    "            duration = finish-begin\n",
    "            print(f\"Done training Model {t}_{j} seed {seed}. End: {end.strftime('%d.%m.%Y %H:%M:%S')}\")\n",
    "            print(f\"Duration: {end-start}\")\n",
    "            model.save(model_save)\n",
    "            \n",
    "            test_data = test_coordinates(env, model, coordinates)\n",
    "            with open(os.path.join(savedir,'test_data.pkl'), 'wb') as file:\n",
    "                pickle.dump(test_data, file)\n",
    "                    \n",
    "            successes = np.array(test_data[\"successes\"])\n",
    "            failures = np.array(test_data[\"failures\"])\n",
    "            timeouts = np.array(test_data[\"timeouts\"])\n",
    "            # fig = visualize_tests_2D(env, successes, failures, timeouts)\n",
    "            # plt.savefig(os.path.join(savedir,\"CDPR2T_.png\"), format=\"png\",dpi=150)\n",
    "            # plt.close()\n",
    "            test_table = {\n",
    "                \"Y\":[], \n",
    "                \"Z\":[],\n",
    "                \"success\":[],\n",
    "                \"timeout\":[],\n",
    "                \"failure\":[],\n",
    "                \"duration\":[],\n",
    "                \"brake_time\":[],\n",
    "                \"deceleration_time\":[],\n",
    "                'rms_jerk':[],\n",
    "                # 'max_velocity':[],\n",
    "                # 'rms_velocity':[],\n",
    "                'trajectory_length':[],\n",
    "                'trajectory_distance':[],\n",
    "                'relative_length':[],\n",
    "                'rms_forces':[],\n",
    "                'rms_force_gradients':[],\n",
    "                # 'max_force':[],\n",
    "                'max_force_delta':[],\n",
    "                'continuity_cost':[], \n",
    "                'df_continuity_cost':[]}\n",
    "            # if \"CDPR2T_new.xlsx\" in files:\n",
    "            #     test_table = pd.read_excel(os.path.join(savedir,\"CDPR2T_new.xlsx\"))\n",
    "            # else:\n",
    "            for k, trajectory in enumerate(test_data[\"trajectories\"]):\n",
    "                try:\n",
    "                    poses, velocities, accelerations, forces, success, duration, done = trajectory.values()\n",
    "                except:\n",
    "                    poses, velocities, accelerations, forces, success, duration, done, metrics = trajectory.values()\n",
    "                    \n",
    "                translation_metrics = evaluation.evaluate_translation_trajectory(poses, velocities, accelerations)\n",
    "                force_metrics = evaluation.evaluate_force_trajectory(forces)\n",
    "                cc_mean = evaluation.continuity_cost(forces, env.f_min, env.f_max)\n",
    "                delta_f = np.diff(forces, axis=0)\n",
    "                brake_time = evaluation.find_final_threshold_index(np.linalg.norm(velocities,axis=1),0.1)*env.Ts\n",
    "                deceleration_time = evaluation.find_not_rising_index(np.linalg.norm(velocities,axis=1))*env.Ts\n",
    "                if len(delta_f)>1:\n",
    "                    df_cc_mean = evaluation.continuity_cost(delta_f, -100, 100)\n",
    "                else:\n",
    "                    df_cc_mean = 0\n",
    "                metrics = {}\n",
    "                metrics.update(translation_metrics)\n",
    "                metrics.update(force_metrics)\n",
    "                metrics.update({\"continuity_cost\":cc_mean, \n",
    "                                \"df_continuity_cost\":df_cc_mean,})\n",
    "                trajectory.update({\"metrics\":metrics})\n",
    "                # Viz\n",
    "                y = np.round(poses[0,0])\n",
    "                z = np.round(poses[0,1])\n",
    "                test_table[\"Y\"].append(y)\n",
    "                test_table[\"Z\"].append(z)\n",
    "                test_table[\"success\"].append(success)\n",
    "                test_table[\"timeout\"].append(not done)\n",
    "                test_table[\"failure\"].append(not success and done)\n",
    "                test_table[\"duration\"].append(duration)\n",
    "                test_table[\"brake_time\"].append(brake_time)\n",
    "                test_table[\"deceleration_time\"].append(deceleration_time)\n",
    "                for metric, value in metrics.items():\n",
    "                    if len(metric)==2:\n",
    "                        test_table[metric[0]].append(value[0])\n",
    "                        test_table[metric[1]].append(value[1])\n",
    "                    else:\n",
    "                        test_table[metric].append(value)\n",
    "                if k%2 == 0:\n",
    "                    fig1 = visualize_forces(env, poses[0], Ts, forces)\n",
    "                    fig2 = visualize_velocities(env, poses[0], Ts, velocities)\n",
    "                    fig3 = visualize_poses(env, Ts, poses)\n",
    "                    figs = [fig1, fig2, fig3]\n",
    "                    fig_combi = combine_figures(figs)\n",
    "                    plt.savefig(os.path.join(savedir,(f\"forces_velocities_positions_{y}_{z}.png\")), format=\"png\",dpi=150)\n",
    "                    plt.close('all')\n",
    "\n",
    "            test_table = pd.DataFrame(test_table)\n",
    "            with pd.ExcelWriter(os.path.join(savedir, \"CDPR2T_new.xlsx\")) as writer:\n",
    "                df = pd.DataFrame(test_table)\n",
    "                df.to_excel(writer, sheet_name= \"test\",engine=\"xlsxwriter\")\n",
    "            result = {\n",
    "                \"success_rate\": sum(test_table[\"success\"])/len(test_table[\"success\"]),\n",
    "                \"failure_rate\": sum(test_table[\"failure\"])/len(test_table[\"failure\"]),\n",
    "                \"timeout_rate\": sum(test_table[\"timeout\"])/len(test_table[\"timeout\"]),\n",
    "                \"mean_jerk\": np.mean(test_table[\"rms_jerk\"]),\n",
    "                # \"mean_velocity\": np.mean(test_table[\"rms_velocity\"]),\n",
    "                # \"max_velocity\": np.max(test_table[\"max_velocity\"]),\n",
    "                \"mean_duration\": np.mean(test_table[\"duration\"]),\n",
    "                \"mean_success_duration\": np.mean(test_table[\"duration\"][test_table[\"success\"]]),\n",
    "                \"mean_brake_time\":np.mean(test_table[\"brake_time\"][test_table[\"success\"]]),\n",
    "                \"mean_deceleration_time_time\":np.mean(test_table[\"deceleration_time\"][test_table[\"success\"]]),\n",
    "                \"mean_relative_length\": np.mean(test_table[\"relative_length\"][test_table[\"success\"]]),\n",
    "                \"mean_forces\": np.mean(test_table[\"rms_forces\"]),\n",
    "                \"mean_max_force_delta\": np.mean(test_table[\"max_force_delta\"]),\n",
    "                \"mean_force_delta\": np.mean(test_table[\"rms_force_gradients\"]),\n",
    "                \"mean_continuity_cost\": np.mean(test_table[\"continuity_cost\"]),\n",
    "                \"mean_df_continuity_cost\": np.mean(test_table[\"df_continuity_cost\"]),\n",
    "                \"average_distance_to_centroid\": evaluation.average_distance_to_centroid(successes)\n",
    "                }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('RL1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7841117c228dc0652bf66186b89b18182f15dd6605545d59de012a2de718272f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
